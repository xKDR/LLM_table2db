"""
Karnataka Budget Validation Script
====================================

This script performs hierarchical validation of Karnataka budget data across
5 separate CSV files generated by the extraction workflow:

1. final_sub_major_head_summary.csv - Sub-Major Head level data
2. final_minor_head_summary.csv - Minor Head level data
3. final_sub_head_summary.csv - Sub-Head level data [This file is missing!]
4. final_detailed_head_summary.csv - Detailed Head level data [This file is missing!]
5. final_object_head_summary.csv - Object Head level data (most granular)

Each CSV contains data at its respective hierarchy level, with appropriate
parent hierarchy codes inherited from higher levels.

Validations performed (comprehensive roll-ups):

From Object Head (most granular):
1. Object Head → Detailed Head [Only Validation being done in this file]
2. Object Head → Sub-Head [Skipped]
3. Object Head → Minor Head [Skipped]
4. Object Head → Major Head [Skipped]

From Detailed Head:
5. Detailed Head → Sub-Head [Skipped]
6. Detailed Head → Minor Head [Skipped]
7. Detailed Head → Major Head [Skipped]

From Sub-Head:
8. Sub-Head → Minor Head [Skipped]
9. Sub-Head → Major Head [Skipped]

From Minor Head:
10. Minor Head → Major Head [Skipped]
"""

import argparse
import pandas as pd
import numpy as np
from collections import defaultdict
from pathlib import Path

# Financial columns to validate
FINANCIAL_COLS = ['Accounts_2018_19', 'Budget_2019_20', 'Revised_2019_20', 'Budget_2020_21']

def safe_int(value):
    """
    Safely convert a value to int, handling non-numeric values gracefully.
    Returns 0 if value cannot be converted.
    """
    if pd.isna(value):
        return 0
    value_str = str(value).replace('.', '').replace(' ', '').strip()
    if value_str.isdigit():
        try:
            return int(float(str(value)))
        except (ValueError, TypeError):
            return 0
    return 0

def calculate_accuracy_percentage(calculated_value, reported_value):
    """
    Calculate accuracy percentage based on absolute difference.
    Accuracy % = 100 - (|difference| / |reported_value| * 100)
    Returns 100% if both values are 0, 0% if only reported is 0 but calculated is not.
    """
    if reported_value == 0:
        return 100.0 if calculated_value == 0 else 0.0

    abs_diff = abs(calculated_value - reported_value)
    error_pct = (abs_diff / abs(reported_value)) * 100
    accuracy_pct = max(0, 100 - error_pct)
    return accuracy_pct

def clean_non_english(text):
    """Remove non-English (non-ASCII) characters from text"""
    if pd.isna(text):
        return ''
    cleaned = ''.join(c for c in str(text) if ord(c) < 128)
    cleaned = ' '.join(cleaned.split())
    return cleaned.strip()

def load_and_clean_data(csv_path):
    """Load CSV file and clean non-English characters"""
    df = pd.read_csv(csv_path)

    # Clean non-English characters from text fields
    text_fields = ['Description', 'Major_Head_Name', 'Sub_Major_Head_Name',
                   'Minor_Head_Name', 'Sub_Head_Name', 'Detailed_Head_Name',
                   'Object_Head_Description']

    for field in text_fields:
        if field in df.columns:
            df[field] = df[field].apply(clean_non_english)

    # Remove rows where Description is empty after cleaning
    df = df[df['Description'] != ''].copy()

    # Remove duplicate rows based on key columns
    key_cols = ['Source_Page_Number', 'Major_Head_Code', 'Full_Account_Code',
                'Vote_Charge_Marker', 'Description', 'Row_Type', 'Row_Level']
    df = df.drop_duplicates(
        subset=[col for col in key_cols if col in df.columns],
        keep='first'
    )

    # Convert financial columns to numeric, handling errors
    for col in FINANCIAL_COLS:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # Fill NaN for Vote_Charge_Marker with empty string
    if 'Vote_Charge_Marker' in df.columns:
        df['Vote_Charge_Marker'] = df['Vote_Charge_Marker'].fillna('')

    return df

def validation_object_to_detailed(object_df):
    """
    Validation 1: Object Head Data → Detailed Head Total
    Sum all Object Head Data rows, grouped by hierarchy up to Detailed Head
    Compare to Detailed Head Totals (V + C combined)
    """
    results = []

    # Get Object Head Data rows
    object_data = object_df[
        (object_df['Row_Type'] == 'Data') &
        (object_df['Row_Level'] == 'Object-Head')
    ].copy()

    # Sum by Major + Minor + Sub + Detailed (combining V and C)
    object_sums = defaultdict(lambda: {col: 0 for col in FINANCIAL_COLS})
    object_counts = defaultdict(int)

    for _, row in object_data.iterrows():
        # Safely convert codes to int, handling non-numeric values
        major = safe_int(row.get('Major_Head_Code'))
        minor = safe_int(row.get('Minor_Head_Code'))
        sub = safe_int(row.get('Sub_Head_Code'))
        detailed = safe_int(row.get('Detailed_Head_Code'))

        # Skip if all codes are 0 (likely invalid row)
        if major == 0 and minor == 0 and sub == 0 and detailed == 0:
            continue

        key = (major, minor, sub, detailed)

        for col in FINANCIAL_COLS:
            object_sums[key][col] += row[col]
        object_counts[key] += 1

    # Get Detailed Head Totals
    detailed_totals = object_df[
        (object_df['Row_Type'] == 'Total') &
        (object_df['Row_Level'] == 'Detailed-Head')
    ].copy()

    # Group detailed totals, summing V and C together
    detailed_total_sums = defaultdict(lambda: {col: 0 for col in FINANCIAL_COLS})
    detailed_total_info = {}

    for _, total_row in detailed_totals.iterrows():
        # Safely convert codes to int, handling non-numeric values
        major = safe_int(total_row.get('Major_Head_Code'))
        minor = safe_int(total_row.get('Minor_Head_Code'))
        sub = safe_int(total_row.get('Sub_Head_Code'))
        detailed = safe_int(total_row.get('Detailed_Head_Code'))

        # Skip if all codes are 0 (likely invalid row)
        if major == 0 and minor == 0 and sub == 0 and detailed == 0:
            continue

        key = (major, minor, sub, detailed)

        for col in FINANCIAL_COLS:
            detailed_total_sums[key][col] += total_row[col]

        if key not in detailed_total_info:
            detailed_total_info[key] = {
                'description': total_row['Description'],
                'page': total_row['Source_Page_Number']
            }

    # Compare
    for key in object_sums:
        if key not in detailed_total_sums:
            continue

        major, minor, sub, detailed = key
        calc_vals = object_sums[key]
        total_vals = detailed_total_sums[key]

        result = {
            'Validation': 'Object Head Data → Detailed Head Total',
            'Major_Head': major,
            'Minor_Head': minor,
            'Sub_Head': sub,
            'Detailed_Head': detailed,
            'Vote_Charge': 'V+C',
            'Description': detailed_total_info[key]['description'],
            'Page': detailed_total_info[key]['page'],
            'Object_Count': object_counts[key],
        }

        all_match = True
        total_abs_diff = 0
        accuracy_sum = 0
        for col in FINANCIAL_COLS:
            calc = calc_vals[col]
            reported = total_vals[col]
            diff = calc - reported
            abs_diff = abs(diff)
            accuracy = calculate_accuracy_percentage(calc, reported)

            result[f'{col}_ObjectSum'] = round(calc, 2)
            result[f'{col}_DetailedTotal'] = round(reported, 2)
            result[f'{col}_Diff'] = round(diff, 2)
            result[f'{col}_AbsDiff'] = round(abs_diff, 2)
            result[f'{col}_Accuracy_%'] = round(accuracy, 2)
            result[f'{col}_Match'] = 'PASS' if abs_diff < 0.01 else 'FAIL'

            total_abs_diff += abs_diff
            accuracy_sum += accuracy
            if abs_diff >= 0.01:
                all_match = False

        result['Total_AbsDiff'] = round(total_abs_diff, 2)
        result['Avg_Accuracy_%'] = round(accuracy_sum / len(FINANCIAL_COLS), 2)
        result['Status'] = 'PASS' if all_match else 'FAIL'
        results.append(result)

    return pd.DataFrame(results)

# <<< NEW FUNCTION ADDED HERE >>>
def validation_twosource_minorhead(minor_df, object_df):
    """
    Validation 2: Minor Head Data (minor_head.csv) → Minor Head Total (object_head.csv)
    Compares data rows from `minor_head.csv` against total rows from `object_head.csv`
    at the Minor Head level (V + C combined).
    """
    results = []

    # 1. Get Minor Head Data rows from minor_head.csv
    minor_data_rows = minor_df[
        (minor_df['Row_Type'] == 'Data') &
        (minor_df['Row_Level'] == 'Minor-Head')
    ].copy()

    # Sum by Major + Sub_Major + Minor (combining V and C)
    minor_data_sums = defaultdict(lambda: {col: 0 for col in FINANCIAL_COLS})
    minor_data_info = {}

    for _, row in minor_data_rows.iterrows():
        major = safe_int(row.get('Major_Head_Code'))
        sub_major = safe_int(row.get('Sub_Major_Head_Code'))
        minor = safe_int(row.get('Minor_Head_Code'))

        if major == 0 and sub_major == 0 and minor == 0:
            continue

        key = (major, sub_major, minor)

        for col in FINANCIAL_COLS:
            minor_data_sums[key][col] += row[col]
        
        if key not in minor_data_info:
            minor_data_info[key] = {
                'description': row['Description'],
                'page': row['Source_Page_Number']
            }

    # 2. Get Minor Head Total rows from object_head.csv
    # <<< MODIFICATION IS HERE >>>
    # Define the regex pattern: "Total" + space + 3 digits (e.g., "Total 101")
    # ^ anchors to start, \s+ allows one or more spaces, \d{3} is 3 digits, $ anchors to end
    regex_pattern = r'^Total\s+\d{3}$'
    
    object_total_rows = object_df[
        (object_df['Row_Type'] == 'Total') &
        (object_df['Row_Level'] == 'Minor-Head') &
        # Apply the regex filter to the Description column
        (object_df['Description'].str.match(regex_pattern, na=False))
    ].copy()
    # <<< END OF MODIFICATION >>>


    # Group object totals, summing V and C together
    object_total_sums = defaultdict(lambda: {col: 0 for col in FINANCIAL_COLS})

    for _, total_row in object_total_rows.iterrows():
        major = safe_int(total_row.get('Major_Head_Code'))
        sub_major = safe_int(total_row.get('Sub_Major_Head_Code'))
        minor = safe_int(total_row.get('Minor_Head_Code'))

        if major == 0 and sub_major == 0 and minor == 0:
            continue

        key = (major, sub_major, minor)

        for col in FINANCIAL_COLS:
            object_total_sums[key][col] += total_row[col]

    # 3. Compare (Looping over data from minor_head.csv as the source)
    for key in minor_data_sums:
        if key not in object_total_sums:
            # This data row in minor_head.csv has no corresponding
            # total row in object_head.csv. We can't validate it.
            continue

        major, sub_major, minor = key
        data_vals = minor_data_sums[key]
        total_vals = object_total_sums[key]

        result = {
            'Validation': 'Minor Head Data → Object Head Total',
            'Major_Head': major,
            'Sub_Major_Head': sub_major,
            'Minor_Head': minor,
            'Vote_Charge': 'V+C',
            'Description': minor_data_info[key]['description'],
            'Page': minor_data_info[key]['page'],
        }

        all_match = True
        total_abs_diff = 0
        accuracy_sum = 0
        for col in FINANCIAL_COLS:
            # 'calc' is the value from minor_head.csv (Data)
            calc = data_vals[col]
            # 'reported' is the value from object_head.csv (Total)
            reported = total_vals[col]
            diff = calc - reported
            abs_diff = abs(diff)
            accuracy = calculate_accuracy_percentage(calc, reported)

            result[f'{col}_MinorDataSum'] = round(calc, 2)
            result[f'{col}_ObjectTotal'] = round(reported, 2)
            result[f'{col}_Diff'] = round(diff, 2)
            result[f'{col}_AbsDiff'] = round(abs_diff, 2)
            result[f'{col}_Accuracy_%'] = round(accuracy, 2)
            result[f'{col}_Match'] = 'PASS' if abs_diff < 0.01 else 'FAIL'

            total_abs_diff += abs_diff
            accuracy_sum += accuracy
            if abs_diff >= 0.01:
                all_match = False

        result['Total_AbsDiff'] = round(total_abs_diff, 2)
        result['Avg_Accuracy_%'] = round(accuracy_sum / len(FINANCIAL_COLS), 2)
        result['Status'] = 'PASS' if all_match else 'FAIL'
        results.append(result)

    return pd.DataFrame(results)# <<< END OF NEW FUNCTION >>>


def create_summary_stats(df_list, names, sources):
    """Create summary statistics across all validations"""
    summary = []
    overall_total_checks = 0
    overall_passed = 0
    overall_avg_accuracy_sum = 0.0
    overall_avg_accuracy_count = 0
    overall_abs_diff = {col: 0.0 for col in FINANCIAL_COLS}
    overall_accuracy_sum = {col: 0.0 for col in FINANCIAL_COLS}
    overall_accuracy_count = {col: 0 for col in FINANCIAL_COLS}

    for df, name, source in zip(df_list, names, sources):
        if df.empty:
            row = {
                'Validation_Type': name,
                'Source_File': source,
                'Total_Checks': 0,
                'Passed': 0,
                'Failed': 0,
                'Pass_Rate_%': 0
            }
            # Add absolute delta columns
            for col in FINANCIAL_COLS:
                row[f'{col}_Total_AbsDiff'] = 0.0
                row[f'{col}_Avg_Accuracy_%'] = 0.0
            row['Total_AbsDiff_All_Columns'] = 0.0
            row['Overall_Avg_Accuracy_%'] = 0.0
            summary.append(row)
            continue

        total = len(df)
        passed = len(df[df['Status'] == 'PASS'])
        failed = len(df[df['Status'] == 'FAIL'])
        pass_rate = (passed / total * 100) if total > 0 else 0

        overall_total_checks += total
        overall_passed += passed

        row = {
            'Validation_Type': name,
            'Source_File': source,
            'Total_Checks': total,
            'Passed': passed,
            'Failed': failed,
            'Pass_Rate_%': round(pass_rate, 2)
        }

        # Calculate total absolute differences for each financial column
        total_all_cols = 0
        for col in FINANCIAL_COLS:
            abs_diff_col = f'{col}_AbsDiff'
            if abs_diff_col in df.columns:
                total_abs_diff = df[abs_diff_col].sum()
                row[f'{col}_Total_AbsDiff'] = round(total_abs_diff, 2)
                total_all_cols += total_abs_diff
                overall_abs_diff[col] += total_abs_diff
            else:
                row[f'{col}_Total_AbsDiff'] = 0.0

        # Add total across all financial columns
        row['Total_AbsDiff_All_Columns'] = round(total_all_cols, 2)

        # Calculate average accuracy percentages for each financial column
        for col in FINANCIAL_COLS:
            accuracy_col = f'{col}_Accuracy_%'
            if accuracy_col in df.columns:
                avg_accuracy = df[accuracy_col].mean()
                # accumulate for overall metrics
                overall_accuracy_sum[col] += df[accuracy_col].sum()
                overall_accuracy_count[col] += df[accuracy_col].count()
                row[f'{col}_Avg_Accuracy_%'] = round(avg_accuracy, 2)
            else:
                row[f'{col}_Avg_Accuracy_%'] = 0.0

        # Calculate overall average accuracy across all columns
        if 'Avg_Accuracy_%' in df.columns:
            overall_avg_accuracy = df['Avg_Accuracy_%'].mean()
            row['Overall_Avg_Accuracy_%'] = round(overall_avg_accuracy, 2)
            overall_avg_accuracy_sum += df['Avg_Accuracy_%'].sum()
            overall_avg_accuracy_count += df['Avg_Accuracy_%'].count()
        else:
            row['Overall_Avg_Accuracy_%'] = 0.0

        summary.append(row)

    # Append an overall accuracy row aggregating across validations
    overall_failed = max(overall_total_checks - overall_passed, 0)
    overall_pass_rate = (overall_passed / overall_total_checks * 100) if overall_total_checks > 0 else 0.0
    overall_row = {
        'Validation_Type': 'Overall Accuracy',
        'Source_File': 'ALL',
        'Total_Checks': overall_total_checks,
        'Passed': overall_passed,
        'Failed': overall_failed,
        'Pass_Rate_%': round(overall_pass_rate, 2),
    }

    total_abs_all_columns = 0.0
    for col in FINANCIAL_COLS:
        total_abs = overall_abs_diff[col]
        total_abs_all_columns += total_abs
        overall_row[f'{col}_Total_AbsDiff'] = round(total_abs, 2)
        if overall_accuracy_count[col] > 0:
            avg_acc = overall_accuracy_sum[col] / overall_accuracy_count[col]
            overall_row[f'{col}_Avg_Accuracy_%'] = round(avg_acc, 2)
        else:
            overall_row[f'{col}_Avg_Accuracy_%'] = 0.0

    overall_row['Total_AbsDiff_All_Columns'] = round(total_abs_all_columns, 2)
    if overall_avg_accuracy_count > 0:
        overall_avg = overall_avg_accuracy_sum / overall_avg_accuracy_count
        overall_row['Overall_Avg_Accuracy_%'] = round(overall_avg, 2)
    else:
        overall_row['Overall_Avg_Accuracy_%'] = 0.0

    summary.append(overall_row)

    return pd.DataFrame(summary)

def main(output_dir=None, output_prefix='validation'):
    """
    Main validation function.

    Loads the 5 separate CSV files generated by extract_workflow.py and
    performs hierarchical validation from most granular (Object Head) to
    least granular (Major Head).

    Args:
        output_dir: Directory to save validation results (default: OUT/15_sr_ka_exp)
        output_prefix: Prefix for output filenames (default: 'validation')

    Returns:
        Tuple of (validations, summary) DataFrames
    """

    # Argument handling
    parser = argparse.ArgumentParser(
        prog="run_validation",
        description='Main validation function for going through all 5 csv types')
    parser.add_argument('-o', '--out-path',
                        default="OUT/15_viki_ka_exp/03-EXPVOL-01-1",
                        help='Base output TO where we extract files')
    args = parser.parse_args()
    config = {}

    # Get project root (two levels up from this file)
    config['PROJECT_ROOT'] = Path(__file__).parent.parent.parent

    # Get configuration options here.
    config['OUTPUT_BASE'] = config['PROJECT_ROOT'] / args.out_path

    OUT_DIR = config['OUTPUT_BASE']

    print("=" * 80)
    print("KARNATAKA BUDGET COMPREHENSIVE VALIDATION")
    print("=" * 80)

    # Load all CSV files - updated paths to match new naming convention
    print("\n1. Loading data files...")

    csv_files = {
        'sub_major_head': OUT_DIR / 'final_sub_major_head_summary.csv',
        'minor_head': OUT_DIR / 'final_minor_head_summary.csv',
        'sub_head': OUT_DIR / 'final_sub_head_summary.csv',
        'detailed_head': OUT_DIR / 'final_detailed_head_summary.csv',
        'object_head': OUT_DIR / 'final_object_head_summary.csv',
    }

    loaded_dfs = {}
    for key, path in csv_files.items():
        if path.exists():
            df = load_and_clean_data(path)
            loaded_dfs[key] = df
            print(f"   ✓ Loaded {len(df)} rows from {path.name}")
        else:
            print(f"   ⚠ File not found: {path.name}")

    print("\n2. Running comprehensive hierarchical validations...")
    print("   (10 validations from most granular to top level)\n")

    validations = []
    val_names = []
    val_sources = []

    # === FROM OBJECT HEAD (Most Granular) ===
    if 'object_head' in loaded_dfs:
        print("   From Object Head:")
        print("   → Validation 1: Object Head → Detailed Head...")
        val1 = validation_object_to_detailed(loaded_dfs['object_head'])
        validations.append(val1)
        val_names.append('Object → Detailed')
        val_sources.append('object_head_summary.csv')
    
    # <<< NEW VALIDATION BLOCK ADDED HERE >>>
    # === CROSS-FILE VALIDATIONS ===
    if 'minor_head' in loaded_dfs and 'object_head' in loaded_dfs:
        print("   Cross-File:")
        print("   → Validation 2: Minor Head Data (minor.csv) → Object Head Total (object.csv)...")
        val2 = validation_twosource_minorhead(loaded_dfs['minor_head'], loaded_dfs['object_head'])
        validations.append(val2)
        val_names.append('Twosource Minor Head')
        val_sources.append('minor_head + object_head')
    # <<< END OF NEW VALIDATION BLOCK >>>


    if not validations:
        print("\n❌ No validations could be performed. Please check input files.")
        return None

    print("\n3. Generating summary...")
    summary = create_summary_stats(validations, val_names, val_sources)

    # Determine output directory
    if output_dir is None:
        output_dir = OUT_DIR
    else:
        output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Save outputs
    print("\n4. Saving validation results...")
    output_files = []
    for i, (val_df, val_name) in enumerate(zip(validations, val_names), 1):
        # Create a clean filename for the validation
        clean_val_name = val_name.lower().replace(" → ", "_to_").replace(" ", "_").replace("(", "").replace(")", "").replace(".csv", "")
        output_path = output_dir / f'{output_prefix}_{i}_{clean_val_name}.csv'
        val_df.to_csv(output_path, index=False)
        output_files.append(output_path)
        print(f"   ✓ {output_path}")

    summary_path = output_dir / f'{output_prefix}_summary.csv'
    summary.to_csv(summary_path, index=False)
    print(f"   ✓ {summary_path}")

    print("\n" + "=" * 80)
    print("VALIDATION SUMMARY")
    print("=" * 80)
    print(summary.to_string(index=False))

    # Highlight accuracy metrics within the summary
    accuracy_columns = [
        'Validation_Type',
        'Total_Checks',
        'Passed',
        'Failed',
        'Pass_Rate_%',
        'Overall_Avg_Accuracy_%',
    ] + [f'{col}_Avg_Accuracy_%' for col in FINANCIAL_COLS]
    accuracy_columns = [col for col in accuracy_columns if col in summary.columns]
    if accuracy_columns:
        accuracy_view = summary[accuracy_columns]
        print("\n" + "=" * 80)
        print("ACCURACY SUMMARY BY VALIDATION")
        print("=" * 80)
        print(accuracy_view.to_string(index=False))

    # Dedicated overall accuracy report section
    overall_row = summary[summary['Validation_Type'] == 'Overall Accuracy']
    if not overall_row.empty:
        overall_columns = [
            'Validation_Type',
            'Total_Checks',
            'Passed',
            'Failed',
            'Pass_Rate_%',
            'Overall_Avg_Accuracy_%',
            'Total_AbsDiff_All_Columns',
        ]
        for col in FINANCIAL_COLS:
            overall_columns.append(f'{col}_Avg_Accuracy_%')
            overall_columns.append(f'{col}_Total_AbsDiff')
        overall_columns = [col for col in overall_columns if col in overall_row.columns]

        print("\n" + "=" * 80)
        print("OVERALL ACCURACY REPORT")
        print("=" * 80)
        print(overall_row[overall_columns].to_string(index=False))

    # Display sample failures
    for val_df, val_name in zip(validations, val_names):
        if not val_df.empty:
            failures = val_df[val_df['Status'] == 'FAIL']
            if not failures.empty:
                print(f"\n{'=' * 80}")
                print(f"FAILURES IN: {val_name}")
                print("=" * 80)
                # Select key columns for display
                key_cols = ['Major_Head', 'Description', 'Page', 'Status']
                match_cols = [f'{col}_Match' for col in FINANCIAL_COLS]
                display_cols = [c for c in key_cols + match_cols if c in failures.columns]
                print(failures[display_cols].head(10).to_string(index=False))
                if len(failures) > 10:
                    print(f"\n... and {len(failures) - 10} more failures")

    print("\n" + "=" * 80)
    print("VALIDATION COMPLETE")
    print("=" * 80)

    return validations, summary

if __name__ == "__main__":
    main()